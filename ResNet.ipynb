{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/arkanivasarkar/Retinal-Vessel-Segmentation-using-variants-of-UNET/blob/main/model.py"
      ],
      "metadata": {
        "id": "EBZQYpzH-k-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training:\n",
        "32 Drive (20 training + 12 test)\n",
        "23 Chasedb1 (12_L)\n",
        "36 HRF (12_h)\n",
        "7 FA\n",
        "= 98\n",
        "Test:\n",
        "8 Drive\n",
        "5 ChaseDB1\n",
        "9 HRF\n",
        "1 FA\n",
        "= 23"
      ],
      "metadata": {
        "id": "GoKvRIcjzxzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xmlXbI69c8Z",
        "outputId": "f3307e40-9ece-40bb-caa7-7c6af17e56c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patchify in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from patchify) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T9ZccSV-yPL",
        "outputId": "a5671d68-a102-4810-db12-c5267a4e70a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecodecs"
      ],
      "metadata": {
        "id": "luypQ_X-NLsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imagecodecs"
      ],
      "metadata": {
        "id": "dCi6eZcNNG9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpiGiGp-7FPy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify, unpatchify\n",
        "from PIL import Image\n",
        "np.random.seed(0)\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import jaccard_score,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CLAHE\n",
        "def clahe_equalized(imgs):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    imgs_equalized = clahe.apply(imgs)\n",
        "    return imgs_equalized"
      ],
      "metadata": {
        "id": "2j7ORg6F81NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UojYYBmwOgx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(x)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(conv)\n",
        "    if batchnorm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    return conv\n",
        "\n",
        "\n",
        "#residual convolutional block\n",
        "def res_conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
        "    conv1 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        conv1 = layers.BatchNormalization(axis=3)(conv1)\n",
        "    conv1 = layers.Activation('relu')(conv1)\n",
        "    conv2 = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding='same')(conv1)\n",
        "    if batchnorm is True:\n",
        "        conv2 = layers.BatchNormalization(axis=3)(conv2)\n",
        "        conv2 = layers.Activation(\"relu\")(conv2)\n",
        "    if dropout > 0:\n",
        "        conv2 = layers.Dropout(dropout)(conv2)\n",
        "\n",
        "    #skip connection\n",
        "    shortcut = layers.Conv2D(filters, kernel_size=(1, 1), kernel_initializer='he_normal', padding='same')(x)\n",
        "    if batchnorm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "    shortcut = layers.Activation(\"relu\")(shortcut)\n",
        "    respath = layers.add([shortcut, conv2])\n",
        "    return respath\n",
        "\n",
        "\n",
        "#gating signal for attention unit\n",
        "def gatingsignal(input, out_size, batchnorm=False):\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batchnorm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "#attention unit/block based on soft attention\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), kernel_initializer='he_normal', padding='same')(x)\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), kernel_initializer='he_normal', padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3), strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]), kernel_initializer='he_normal', padding='same')(phi_g)\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), kernel_initializer='he_normal', padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
        "    upsample_psi = layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': shape_x[3]})(upsample_psi)\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), kernel_initializer='he_normal', padding='same')(y)\n",
        "    attenblock = layers.BatchNormalization()(result)\n",
        "    return attenblock"
      ],
      "metadata": {
        "id": "-gHdRDjb-UBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unetmodel(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, dn_4], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, dn_3], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, dn_2], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, dn_1], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "heomnkZx-Kys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residualunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_conv1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    dn_pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv1)\n",
        "\n",
        "    dn_conv2 = res_conv_block(dn_pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    dn_pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv2)\n",
        "\n",
        "    dn_conv3 = res_conv_block(dn_pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    dn_pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv3)\n",
        "\n",
        "    dn_conv4 = res_conv_block(dn_pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    dn_pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_conv4)\n",
        "\n",
        "    dn_conv5 = res_conv_block(dn_pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # upsampling layers\n",
        "    up_conv6 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_conv5)\n",
        "    up_conv6 = layers.concatenate([up_conv6, dn_conv4], axis=3)\n",
        "    up_conv6 = res_conv_block(up_conv6, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    up_conv7 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv6)\n",
        "    up_conv7 = layers.concatenate([up_conv7, dn_conv3], axis=3)\n",
        "    up_conv7 = res_conv_block(up_conv7, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    up_conv8 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv7)\n",
        "    up_conv8 = layers.concatenate([up_conv8, dn_conv2], axis=3)\n",
        "    up_conv8 = res_conv_block(up_conv8, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    up_conv9 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv8)\n",
        "    up_conv9 = layers.concatenate([up_conv9, dn_conv1], axis=3)\n",
        "    up_conv9 = res_conv_block(up_conv9, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv9)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "mDciXrbj-ZTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attentionunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool_1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = conv_block(pool_1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool_2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = conv_block(pool_2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool_3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = conv_block(pool_3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool_4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = conv_block(pool_4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "3vJtJgFs-ciC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_residualunet(input_shape, dropout=0.2, batchnorm=True):\n",
        "\n",
        "    filters = [16, 32, 64, 128, 256]\n",
        "    kernelsize = 3\n",
        "    upsample_size = 2\n",
        "\n",
        "    inputs = layers.Input(input_shape)\n",
        "\n",
        "    # Downsampling layers\n",
        "    dn_1 = res_conv_block(inputs, kernelsize, filters[0], dropout, batchnorm)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2,2))(dn_1)\n",
        "\n",
        "    dn_2 = res_conv_block(pool1, kernelsize, filters[1], dropout, batchnorm)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2,2))(dn_2)\n",
        "\n",
        "    dn_3 = res_conv_block(pool2, kernelsize, filters[2], dropout, batchnorm)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2,2))(dn_3)\n",
        "\n",
        "    dn_4 = res_conv_block(pool3, kernelsize, filters[3], dropout, batchnorm)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2,2))(dn_4)\n",
        "\n",
        "    dn_5 = res_conv_block(pool4, kernelsize, filters[4], dropout, batchnorm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    gating_5 = gatingsignal(dn_5, filters[3], batchnorm)\n",
        "    att_5 = attention_block(dn_4, gating_5, filters[3])\n",
        "    up_5 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(dn_5)\n",
        "    up_5 = layers.concatenate([up_5, att_5], axis=3)\n",
        "    up_conv_5 = res_conv_block(up_5, kernelsize, filters[3], dropout, batchnorm)\n",
        "\n",
        "    gating_4 = gatingsignal(up_conv_5, filters[2], batchnorm)\n",
        "    att_4 = attention_block(dn_3, gating_4, filters[2])\n",
        "    up_4 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_5)\n",
        "    up_4 = layers.concatenate([up_4, att_4], axis=3)\n",
        "    up_conv_4 = res_conv_block(up_4, kernelsize, filters[2], dropout, batchnorm)\n",
        "\n",
        "    gating_3 = gatingsignal(up_conv_4, filters[1], batchnorm)\n",
        "    att_3 = attention_block(dn_2, gating_3, filters[1])\n",
        "    up_3 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_4)\n",
        "    up_3 = layers.concatenate([up_3, att_3], axis=3)\n",
        "    up_conv_3 = res_conv_block(up_3, kernelsize, filters[1], dropout, batchnorm)\n",
        "\n",
        "    gating_2 = gatingsignal(up_conv_3, filters[0], batchnorm)\n",
        "    att_2 = attention_block(dn_1, gating_2, filters[0])\n",
        "    up_2 = layers.UpSampling2D(size=(upsample_size, upsample_size), data_format=\"channels_last\")(up_conv_3)\n",
        "    up_2 = layers.concatenate([up_2, att_2], axis=3)\n",
        "    up_conv_2 = res_conv_block(up_2, kernelsize, filters[0], dropout, batchnorm)\n",
        "\n",
        "    conv_final = layers.Conv2D(1, kernel_size=(1,1))(up_conv_2)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    outputs = layers.Activation('sigmoid')(conv_final)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "SGD7Xdeh-ht6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def IoU_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "def IoU_loss(y_true, y_pred):\n",
        "    return -IoU_coef(y_true, y_pred)\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "    acc = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
        "    return acc\n",
        "\n",
        "def IoU(y_true, y_pred, labels = [0, 1]):\n",
        "   IoU = []\n",
        "   for label in labels:\n",
        "      jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='weighted')\n",
        "      IoU.append(jaccard)\n",
        "   return np.mean(IoU)"
      ],
      "metadata": {
        "id": "ejYqIFBS-4bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 256"
      ],
      "metadata": {
        "id": "lL-rNHHx5ufo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = patch_size\n",
        "IMG_WIDTH = patch_size\n",
        "IMG_CHANNELS = 1\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
      ],
      "metadata": {
        "id": "KXl5K64e5swE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "vQB84fq_5hCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# del image_dataset\n",
        "# del mask_dataset"
      ],
      "metadata": {
        "id": "6eEUBhiyCrZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/drive/My Drive/dataset/training15' #training images directory\n",
        "path2 = '/content/drive/My Drive/dataset/masks1' #training masks directory\n",
        "\n",
        "image_dataset = []\n",
        "mask_dataset = []"
      ],
      "metadata": {
        "id": "X7bLbKws84WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = sorted(os.listdir(path1))\n",
        "for i, image_name in enumerate(images):\n",
        "  #if image_name.startswith(\"Chase\") or image_name.startswith(\"DRIVE\"):\n",
        "       image = skimage.io.imread(path1+\"/\"+image_name)  #Read image\n",
        "       #image = image[:,:,1] #selecting green channel\n",
        "      #  image = cv2.resize(image,(2816,4096))\n",
        "       #image = clahe_equalized(image) #applying CLAHE\n",
        "       SIZE_X = (image.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "       SIZE_Y = (image.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "       image = Image.fromarray(image)\n",
        "       image = image.resize((SIZE_X, SIZE_Y)) #resize image\n",
        "       image = np.array(image)\n",
        "       patches_img = patchify(image, (patch_size, patch_size), step=patch_size)  #create patches(patch_sizexpatch_sizex1)\n",
        "       print(patches_img.shape)\n",
        "\n",
        "       for i in range(patches_img.shape[0]):\n",
        "           for j in range(patches_img.shape[1]):\n",
        "               single_patch_img = patches_img[i,j,:,:]\n",
        "               single_patch_img = clahe_equalized(single_patch_img)\n",
        "               single_patch_img = (single_patch_img.astype('float32')) / 255.\n",
        "               image_dataset.append(single_patch_img)"
      ],
      "metadata": {
        "id": "y_9rszIj9OkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masks = sorted(os.listdir(path2))\n",
        "for i, mask_name in enumerate(masks):\n",
        "    #if mask_name.startswith(\"Chase\") or mask_name.startswith(\"DRIVE\"):\n",
        "        mask = skimage.io.imread(path2+\"/\"+mask_name)   #Read masks\n",
        "        mask = mask.astype(np.uint8)\n",
        "        # mask = cv2.resize(mask,(2816,4096))\n",
        "        SIZE_X = (mask.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "        SIZE_Y = (mask.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "        mask = Image.fromarray(mask)\n",
        "        mask = mask.resize((SIZE_X, SIZE_Y))  #resize image\n",
        "        mask = np.array(mask)\n",
        "        if mask.ndim == 3:\n",
        "          mask = mask[:,:,0]\n",
        "        patches_mask = patchify(mask, (patch_size, patch_size), step=patch_size)  #create patches(patch_sizexpatch_sizex1)\n",
        "        print(patches_mask.shape)\n",
        "\n",
        "        for i in range(patches_mask.shape[0]):\n",
        "            for j in range(patches_mask.shape[1]):\n",
        "                single_patch_mask = patches_mask[i,j,:,:]\n",
        "                single_patch_mask = (single_patch_mask.astype('float32'))/255.\n",
        "                mask_dataset.append(single_patch_mask)"
      ],
      "metadata": {
        "id": "i0QZPSQx99K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "image_dataset = np.expand_dims(image_dataset,axis=-1)\n",
        "mask_dataset =  np.expand_dims(mask_dataset,axis=-1)"
      ],
      "metadata": {
        "id": "i8Eb90A0-CYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = unetmodel(input_shape)\n",
        "# model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "\n",
        "# model = residualunet(input_shape)\n",
        "# model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "model = attentionunet(input_shape)\n",
        "model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "# model = attention_residualunet(input_shape)\n",
        "# model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])"
      ],
      "metadata": {
        "id": "xvg8I5Y9_ANx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of image_dataset: {len(image_dataset)}\")\n",
        "print(f\"Length of mask_dataset: {len(mask_dataset)}\")"
      ],
      "metadata": {
        "id": "m_SplDDtAzqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data into 70-30 ratio to validate training performance\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "YbQUdueb_H9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    verbose=1,\n",
        "                    batch_size = 4,\n",
        "                    validation_data=(x_test, y_test ),\n",
        "                    shuffle=False,\n",
        "                    epochs=150)\n",
        "\n",
        "#training-validation loss curve\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "as_7qRaj_KPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training-validation accuracy curve\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'y', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wMYOnCa3_M2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training-validation IoU curve\n",
        "iou_coef = history.history['IoU_coef']\n",
        "val_iou_coef = history.history['val_IoU_coef']\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, iou_coef, 'r', label='Training IoU')\n",
        "plt.plot(epochs, val_iou_coef, 'y', label='Validation IoU')\n",
        "plt.title('Training and validation IoU coefficients')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IoU')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y9OirUy2_OxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('/content/drive/MyDrive/dataset/hdf5/retina_attentionUnet_150epochs5.hdf5')"
      ],
      "metadata": {
        "id": "YR7a96_s_Qgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "v6P7Dxhw51B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Epochs: 150, Batch size: 1, Datasets: 4, Patch Size: 512\n",
        "2. Epochs: 150, Batch size: 4, Datasets: 4, Patch Size: 512\n",
        "3. Epochs: 150, Batch size: 16, Datasets: 2 small, Patch Size: 256\n",
        "4. Epochs: 150, Batch size: 4, Datasets: All, Patch Size: 256, patchenh 256\n",
        "5. Epochs: 150, Batch size: 4, Datasets: All, Patch Size: 256, train15"
      ],
      "metadata": {
        "id": "w5vwlb8h9vuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = attentionunet(input_shape)#attention_residualunet(input_shape) #residualunet(input_shape) #unetmodel(input_shape) #//attentionunet(input_shape)/\n",
        "model.compile(optimizer = Adam(lr = 1e-3), loss= IoU_loss, metrics= ['accuracy', IoU_coef])\n",
        "model.load_weights('/content/drive/MyDrive/dataset/hdf5/retina_attentionUnet_150epochs5.hdf5') #loading weights\n"
      ],
      "metadata": {
        "id": "BtF3xSgZ8wPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/drive/My Drive/dataset/test15'    #test dataset images directory path\n",
        "path2 = '/content/drive/My Drive/dataset/masks2'     #test dataset mask directory path"
      ],
      "metadata": {
        "id": "uZ_vSlK9_ptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = '/content/drive/My Drive/dataset/results/'"
      ],
      "metadata": {
        "id": "Pn4fLuOAPC1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del testimg\n",
        "# del ground_truth\n",
        "# del prediction\n",
        "# del global_IoU\n",
        "# del global_accuracy\n"
      ],
      "metadata": {
        "id": "nJP3HPrwezMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testimg = []\n",
        "ground_truth = []\n",
        "prediction = []\n",
        "global_IoU = []\n",
        "global_accuracy = []\n",
        "\n",
        "testimages = sorted(os.listdir(path1))\n",
        "print(testimages)\n",
        "testmasks =  sorted(os.listdir(path2))"
      ],
      "metadata": {
        "id": "BUjmxkTh_y4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 256"
      ],
      "metadata": {
        "id": "GnRWQtpuqWlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx,image_name in enumerate(testimages):\n",
        "   if image_name.startswith(\"Chase\"):\n",
        "      predicted_patches = []\n",
        "      test_img = skimage.io.imread(path1+\"/\"+image_name)\n",
        "      print(image_name)\n",
        "      idxn = image_name.split(\".\")[0]\n",
        "      print(idxn)\n",
        "      test = test_img[:,:,1] #selecting green channel\n",
        "      test = clahe_equalized(test) #applying CLAHE\n",
        "      SIZE_X = (test_img.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "      SIZE_Y = (test_img.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "      test = cv2.resize(test, (SIZE_X, SIZE_Y))\n",
        "      testimg.append(test)\n",
        "      test = np.array(test)\n",
        "\n",
        "      patches = patchify(test, (patch_size, patch_size), step=patch_size) #create patches(patch_sizexpatch_sizex1)\n",
        "\n",
        "      for i in range(patches.shape[0]):\n",
        "                for j in range(patches.shape[1]):\n",
        "                  single_patch = patches[i,j,:,:]\n",
        "                  single_patch = clahe_equalized(single_patch)\n",
        "                  single_patch_norm = (single_patch.astype('float32')) / 255.\n",
        "                  single_patch_norm = np.expand_dims(np.array(single_patch_norm), axis=-1)\n",
        "                  single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
        "                  single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0]).astype(np.uint8) #predict on single patch\n",
        "                  predicted_patches.append(single_patch_prediction)\n",
        "      predicted_patches = np.array(predicted_patches)\n",
        "      predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
        "      reconstructed_image = unpatchify(predicted_patches_reshaped, test.shape) #join patches to form whole img\n",
        "      # plt.imshow(reconstructed_image)\n",
        "      # cv2.imwrite(path3+image_name, reconstructed_image*255)\n",
        "      # a = np.asarray(reconstructed_image)\n",
        "      np.savetxt(path3+image_name.split(\".\")[0]+\".csv\", a, delimiter=\",\")\n",
        "      prediction.append(reconstructed_image)\n",
        "\n",
        "      groundtruth=[]\n",
        "\n",
        "      for i in range(23):\n",
        "        if testmasks[i].startswith(idxn):\n",
        "           groundtruth1 = testmasks[i]\n",
        "           print(groundtruth1)\n",
        "      groundtruth = cv2.imread(path2+'/'+groundtruth1)\n",
        "      if groundtruth.ndim != 2:\n",
        "        groundtruth = groundtruth[:,:,1]\n",
        "\n",
        "      print(path2+'/'+groundtruth1)\n",
        "      SIZE_X = (groundtruth.shape[1]//patch_size)*patch_size\n",
        "      SIZE_Y = (groundtruth.shape[0]//patch_size)*patch_size\n",
        "      print(SIZE_Y)\n",
        "      groundtruth = cv2.resize(groundtruth, (SIZE_X, SIZE_Y))\n",
        "      ground_truth.append(groundtruth)\n",
        "\n",
        "      y_true = groundtruth\n",
        "      y_pred = reconstructed_image\n",
        "      labels = [0, 1]\n",
        "      IoU = []\n",
        "      for label in labels:\n",
        "          jaccard = jaccard_score(y_pred.flatten(),y_true.flatten(), pos_label=label, average='weighted')\n",
        "          IoU.append(jaccard)\n",
        "      IoU = np.mean(IoU) #jacard/IoU of single image\n",
        "      global_IoU.append(IoU)\n",
        "\n",
        "      cm=[]\n",
        "      accuracy = []\n",
        "      cm = confusion_matrix(y_true.flatten(),y_pred.flatten(), labels=[0, 1])\n",
        "      accuracy = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1]) #accuracy of single image\n",
        "      global_accuracy.append(accuracy)"
      ],
      "metadata": {
        "id": "X7RsOAc2PzmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_acc =  np.mean(global_accuracy)\n",
        "mean_IoU = np.mean(global_IoU)\n",
        "\n",
        "print('Average accuracy is',avg_acc)\n",
        "print('mean IoU is',mean_IoU)"
      ],
      "metadata": {
        "id": "DnVwey_t_4cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. 512 All\n",
        "HRF 512: Average accuracy is 0.9946882263553702\n",
        "mean IoU is 0.904998873489633\n",
        "\n",
        "2. 512 All\n",
        "2. DRIVE 32:\n",
        "2. Chase 320: Average accuracy is Average accuracy is 0.9988899557168601\n",
        "mean IoU is 0.9262972304844466\n",
        "2. Chase 512: Average accuracy is 0.9276695251464844\n",
        "mean IoU is 0.9276695251464844\n",
        "2. FA 320: Average accuracy is 0.9854299887577171\n",
        "mean IoU is 0.8321155246466209\n",
        "2. HRF 2336: Average accuracy is 0.981490971546084\n",
        "mean IoU is 0.88640142622687\n",
        "2. HRF 512: Average accuracy is 0.9946882263553702\n",
        "mean IoU is 0.904998873489633\n",
        "2. HRF 256:\n",
        "2. Drive 320 : output\n",
        "Average accuracy is 0.9892573893573826\n",
        "mean IoU is 0.866798246983386\n",
        "2. DRive 128: Average accuracy is 0.9915096016274048\n",
        "mean IoU is 0.8704649621981082\n",
        "\n",
        "3. 32 D C\n",
        "3. Drive 32: Average accuracy is 0.9925645969857715\n",
        "mean IoU is 0.8721533711780849\n",
        "3. Chase 320: 0.9798967673844892\n",
        "mean IoU is 0.8922928354707995\n",
        "3. FA 320: Average accuracy is 0.9808189709466939\n",
        "mean IoU is 0.8822632836667698\n",
        "3. HRF 256:Average accuracy is 0.9998230508464397\n",
        "mean IoU is 0.914260980184035\n",
        "3. HRF 512: 0.989696897257278\n",
        "mean IoU is 0.8964182414299261"
      ],
      "metadata": {
        "id": "_kP-5ScoqRJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#checking segmentation results\n",
        "import random\n",
        "test_img_number = random.randint(0, len(testimg))\n",
        "plt.figure(figsize=(20, 18))\n",
        "plt.subplot(231)\n",
        "plt.title('Test Image')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(testimg[test_img_number])\n",
        "plt.subplot(232)\n",
        "plt.title('Ground Truth')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(ground_truth[test_img_number],cmap='gray')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(prediction[test_img_number],cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ULA_hVVg_7Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "plt.title('Prediction')\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(prediction[test_img_number]*255,cmap='gray')"
      ],
      "metadata": {
        "id": "dD8m7GkXdIa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for idx1, test_name in enumerate(testmasks):\n",
        "#   if test_name.startswith(\"Chase\"):\n"
      ],
      "metadata": {
        "id": "h4JRfXjJH97X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from numpy import genfromtxt"
      ],
      "metadata": {
        "id": "Bgx8quIHW_N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# my_data = genfromtxt('idridrltestfine7.csv', delimiter=',')\n",
        "# my_data = my_data[16:2832,96:4192]\n",
        "# print(my_data.shape)\n",
        "# plt.imshow(my_data)"
      ],
      "metadata": {
        "id": "v4gGJw1yW7FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = np.asarray(prediction)\n",
        "# print(a.shape)\n",
        "# a = np.reshape(a,(SIZE_Y,SIZE_X))\n",
        "# print(a.shape)\n",
        "# np.savetxt(\"pred_img.csv\", a, delimiter=\",\")"
      ],
      "metadata": {
        "id": "S0ABLDYracA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.savetxt(\"pred_enh.csv\", prediction[0], delimiter=\",\")"
      ],
      "metadata": {
        "id": "5jGLUmqhpPCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #prediction on single image\n",
        "# from datetime import datetime\n",
        "# reconstructed_image = []\n",
        "# test_img = skimage.io.imread('/content/drive/My Drive/dataset/test/Image_04L.jpg') #test image\n",
        "\n",
        "# predicted_patches = []\n",
        "# start = datetime.now()\n",
        "\n",
        "# test = test_img[:,:,1] #selecting green channel\n",
        "# test = clahe_equalized(test) #applying CLAHE\n",
        "# SIZE_X = (test_img.shape[1]//patch_size)*patch_size #getting size multiple of patch size\n",
        "# SIZE_Y = (test_img.shape[0]//patch_size)*patch_size #getting size multiple of patch size\n",
        "# test = cv2.resize(test, (SIZE_X, SIZE_Y))\n",
        "# test = np.array(test)\n",
        "# patches = patchify(test, (patch_size, patch_size), step=patch_size) #create patches(patch_sizexpatch_sizex1)"
      ],
      "metadata": {
        "id": "mjEoEVEa_9hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(patches.shape[0]):\n",
        "#       for j in range(patches.shape[1]):\n",
        "#           single_patch = patches[i,j,:,:]\n",
        "#           single_patch_norm = (single_patch.astype('float32')) / 255.\n",
        "#           single_patch_norm = np.expand_dims(np.array(single_patch_norm), axis=-1)\n",
        "#           single_patch_input = np.expand_dims(single_patch_norm, 0)\n",
        "#           single_patch_prediction = (model.predict(single_patch_input)[0,:,:,0] > 0.5).astype(np.uint8) #predict on single patch\n",
        "#           predicted_patches.append(single_patch_prediction)\n",
        "# predicted_patches = np.array(predicted_patches)\n",
        "# predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], patch_size,patch_size) )\n",
        "# reconstructed_image = unpatchify(predicted_patches_reshaped, test.shape) #join patches to form whole img\n"
      ],
      "metadata": {
        "id": "sxYP7PaqAAly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stop = datetime.now()\n",
        "# print('Execution time: ',(stop-start)) #computation time\n",
        "\n",
        "# plt.subplot(121)\n",
        "# plt.title('Test Image')\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])\n",
        "# plt.imshow(test_img)\n",
        "# plt.subplot(122)\n",
        "# plt.title('Prediction')\n",
        "# plt.xticks([])\n",
        "# plt.yticks([])\n",
        "# plt.imshow(reconstructed_image,cmap='gray')\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "gazbYG1yAVrR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}